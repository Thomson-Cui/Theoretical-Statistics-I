{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of a random sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sample\n",
    "Random variables $X_1,...,X_n$ are called a random sample of size $n$ from the population $f(x)$\n",
    "- If $X_1,...X_n$ are\n",
    "    - mutually independent, and\n",
    "    - marginal pmf/pdf of each $X_i$ is $f(x)$\n",
    "    - Alternative name for a random sample:\n",
    "        - Independent and identically distributed (iid) random variables with pdf or pmf $f(x)$\n",
    "        - i.i.d. $f(x)$ = random sample from $f(x)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Samples and Statistical inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We view data as **observations of random variables**\n",
    "- Usually have more than one observation\n",
    "    \n",
    "    $X_1, X_2,..., X_n$\n",
    "\n",
    "    - Can often assume that $X_1,X_2,...,X_n$ is a **random sample**\n",
    "\n",
    "- We model the data by specifiying a joint distribution\n",
    "\n",
    "    $f(x_1,x_2,...,x_n|\\theta)$\n",
    "\n",
    "    - $\\theta$ is unknown\n",
    "    - with the goal of \n",
    "        - learning about (estimating) $\\theta$ and/or\n",
    "        - predicting observations of $X_{n+1},X_{n+2},...$\n",
    "\n",
    "- Use some summary of the data to do this\n",
    "    - Need to find the distribution of that summary $\\to$ **sampling distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: \n",
    "\n",
    "- Say we collected data on temperatures at CLE airport.\n",
    "- Say data points are $X_1 = 11^{\\circ}C, X_2=12^{\\circ}C, X_3=12.2^{\\circ}C,...,X_n=17^{\\circ}C$\n",
    "- We will assume that $X_1,X_2,...,X_n$ are realizations of random variables.\n",
    "\n",
    "    - $X_1,X_2,...,X_n$\n",
    "\n",
    "- If $X_1,X_2,...,X_n$ are random sample from $f(x)$, then $f(x)$ can be seen as the (population) distribution of temperatures at all times at CLE.\n",
    "\n",
    "- Calculate e.g. $\\hat{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_i$\n",
    "\n",
    "- Distribution of $\\hat{X}$ is sampling distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About random samples\n",
    "\n",
    "- Recall: Random variables $X_1,X_2,...,X_n$ are mutually independent iif\n",
    "\n",
    "    $f(x_1,...,x_n)=f_1(x_1)\\times...\\times f_n(x_n)$\n",
    "\n",
    "    where $f_i(x_i)$ is the marginal pdf/pmf of $X_i$.\n",
    "\n",
    "- So, what is the joint pdf/pmf of a random sample from $f(x)$?\n",
    "    - $f_i(x_i)=f(x_i)$ for all $i$, so\n",
    "\n",
    "        $\\begin{aligned}\n",
    "        f(x_1,...,x_n)&=f_1(x_1)\\times\\cdots\\times f_n(x_n)\\\\\n",
    "                      &=f(x_1)\\times\\cdots\\times f(x_n)\\\\\n",
    "                      &=\\sum_{i=1}^{n}f(x_i)\n",
    "        \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutually independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random variables $X_1,...,X_n$ are (mutually) independent iif\n",
    "\n",
    "    $f(x_1,...,x_n)=f_1(x_1)\\times\\cdots\\times f_n(x_n)$\n",
    "\n",
    "    where $f_i(x_i)$ is the marginal pdf/pmf of $X_i$.\n",
    "\n",
    "- $\\Rightarrow$ any subcollection of $X_1,...,X_n$ are also (mutually) independent.\n",
    "\n",
    "- For example:\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    f(x_1,x_2)&=\\int\\cdots\\int f(x_1,...,x_n)dx_3\\cdots dx_4 \\\\\n",
    "              &=\\int\\cdots\\int f_1(x_1)\\times\\cdots\\times f_n(x_n) dx_3\\cdots dx_n\\\\\n",
    "              &=f_1(x_1)f_2(x_2)\\int f_3(x_3)dx_3\\times\\cdots\\times\\int f_n(x_n) dx_n\\\\\n",
    "              &=f_1(x_1)f_2(x_2)\n",
    "    \\end{aligned}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not all **collections** of random variables are random **samples**\n",
    "    - Need both independence and same (marginal) distributions\n",
    "- If population is finite and we sample **without replacement** we don't get a random sample.\n",
    "\n",
    "#### Example:\n",
    "- Draw cards from a standard deck or 52 cards.\n",
    "- Let $X_i=$ the card we get in draw $i$, $i=1,...,10.$\n",
    "- All $X_i$ have the same (marginal) distribution, but they are not independent sicne e.g.:\n",
    "\n",
    "    $P(X_1=3\\spadesuit)=\\frac{1}{52}$\n",
    "\n",
    "    $\\text{But}~P(X_1=3\\spadesuit\\mid X_4=2\\diamondsuit)=\\frac{1}{51}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple random sample\n",
    "\n",
    "- Sampling without replacement from a finite population is a very common.\n",
    "- A **simple random sample** of size $n$, $X_1,...,X_n$ from a finite population of size $N$ comes from a selection procedure were:\n",
    "    - Any subset of $n$ elements have **the same probability** of being selected.\n",
    "- Simple random sample $\\neq$ ramdom sample\n",
    "- If $N$ is huge we have simple random $\\approx$ random sample\n",
    "    - $\\frac{1}{N}\\approx\\frac{1}{N-1}$, \"almost independent!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More definitions\n",
    "\n",
    "#### A Statistic\n",
    "\n",
    "Let\n",
    "- $X_1,...,X_n$ be a random sample of size $n$\n",
    "- $T(x_1,...,x_n)$ be a real-valued (or vector-valued) funtion with domain that includes the sample space of $(X_1,...,X_n)$\n",
    "    - You just have to be able to evaluate $T(X_1,X_2,...,X_n)$ for any possible value of $X_1,...,X_n$.\n",
    "\n",
    "Then\n",
    "- The random variable (or random vector) $Y=T(X_1,...,X_n)$ is called a **statistic**.\n",
    "- The probability distribution of $Y$ is called the sampling distribution of $Y$\n",
    "- In short: A statistic is a function of a random sample.\n",
    "- Note: Cannot be a function of a parameter.\n",
    "- Key points:\n",
    "    - In general, a statistic is a function of a collection of random variables (does not have to be a random sample).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonly seen statistics\n",
    "- Sample mean:\n",
    "\n",
    "    $\\bar{X}=\\frac{1}{n}(X_1+\\cdots+X_n)=\\frac{1}{n}\\sum_{i=1}^n X_i$\n",
    "\n",
    "- Sample variance:\n",
    "\n",
    "    $S^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\bar{X})^2$\n",
    "\n",
    "- Sample standard deviation:\n",
    "\n",
    "    $S=\\sqrt{S^2}$\n",
    "\n",
    "The random variables $\\bar{X}, S^2, S$ all have a sampling distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A lot of Statistical inference is based on sampling distributions\n",
    "- Hence our focus on distribution of functions of random variables!\n",
    "    - A bit easier if we have a random sample\n",
    "- Example: If the mgf for the population exist:\n",
    "\n",
    "Let $X_1,...,X_n$ be a random sample of size $n$ from a population with mgf $M_X(t)$. The mgf of the sample mean is\n",
    "\n",
    "$$M_{\\bar{X}}(t)=(M_X(t/n))^n$$\n",
    "\n",
    "- Only useful if we recognize the mgf on the right side\n",
    "\n",
    "$$\\bar{X}=\\frac{1}{n}X_1+\\cdots+\\frac{1}{n}X_n$$\n",
    "\n",
    "- i.e. $X=b+a_1X_1+\\cdots+a_nX_n,\\,\\forall a_i=\\frac{1}{n},b=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of sampling distributions\n",
    "- Let $X_1,X_2,...,X_n$ be a random sample from $N(\\mu,\\sigma^2)$. What's the distribution of $\\bar{X}$?\n",
    "\n",
    "$$E(\\bar{X})=E(\\frac{1}{n}\\sum_{i=1}^n X_i)=E(\\mu)=\\mu$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "Var(\\bar{X})&=Var(\\frac{1}{n}\\sum_{i=1}^n X_i)\\\\\n",
    "            &=\\frac{1}{n^2}Var(\\sum_{i=1}^n X_i)\\\\\n",
    "            &=\\frac{1}{n^2}\\sum_{i=1}^nVar(X_i)\\\\\n",
    "            &=\\frac{1}{n^2}n \\sigma^{2}\\\\\n",
    "            &=\\frac{\\sigma^2}{n}\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\bar{X}\\sim N(\\mu,\\frac{\\sigma^2}{n})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let $X_1,X_2,...,X_n$ be a random sample from Gamma($\\alpha,\\sigma^2$). What is the distribution of $\\bar{X}$?\n",
    "\n",
    "    MGF of Gamma($\\alpha,\\beta$): $M_X(t)=(\\frac{1}{1-\\beta t})^\\alpha$\n",
    "\n",
    "    $\\Rightarrow M_{\\bar{X}}(t)=(M_X(\\frac{t}{n}))^n=(\\frac{1}{1-\\frac{t\\beta}{n}})^{\\alpha n}$\n",
    "\n",
    "    $\\Rightarrow$ mgf of Gamma($n\\alpha,\\frac{\\beta}{n}$)\n",
    "\n",
    "    $\\Rightarrow \\bar{X}\\sim$ Gamma($\\alpha n,\\frac{\\beta}{n}$) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling distributions: convolution formula\n",
    "E.g. if mgfs are not available, we can use convalution formula.\n",
    "#### Convolution formula\n",
    "Let $X$ and $Y$ be independent random variables with pdfs $f_X(x)$ and $f_Y(y)$. Then the pdf of $Z=X+Y$ is\n",
    "\n",
    "$$f_Z(z)=\\int_{-\\infty}^{\\infty}f_X(w)f_Y(z-w)dw$$\n",
    "\n",
    "- where $w=x$\n",
    "\n",
    "- Proof:\n",
    "\n",
    "    We can use inverse function:\n",
    "\n",
    "    $x=w=h_1(z,w),y=z-x=z-w=h_2(z,w)$\n",
    "\n",
    "    $(X,Y)\\to(Z,W)$\n",
    "\n",
    "    $\\frac{\\partial x}{\\partial z}=0,\\frac{\\partial x}{\\partial w}=1,\\frac{\\partial y}{\\partial z}=1, \\frac{\\partial y}{\\partial w}=-1$\n",
    "\n",
    "    $|J|=|-1\\cdot 0+1\\cdot 1|=1$\n",
    "\n",
    "    $f_{XY}(x,y)=f_{X}(x)f_{Y}(y)$\n",
    "\n",
    "    Therefore, $f_{ZW}(z,w)=f_X(w)f_Y(z-w)|-1|$\n",
    "\n",
    "    $f_Z(z)=\\int_{-\\infty}^{\\infty}f(z,w)dw=\\int_{-\\infty}^{\\infty}f_X(w)f_Y(z-w)dw$\n",
    "\n",
    "- When $n>2$, just iterate:\n",
    "\n",
    "    $Z_1=X_1+X_2$\n",
    "\n",
    "    $Z_2=X_1+X_2+X_3=Z_1+X_3$\n",
    "\n",
    "    $\\vdots$\n",
    "\n",
    "    $Z_n=Z_{n-1}+X_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moments of sampling distributions\n",
    "\n",
    "#### Lemma\n",
    "\n",
    "Let $X_1,...,X_n$ be a random sample of size $n$ from a population and let $g(x)$ be a function such that $E(g(X_1))$ and $Var(g(X_1))$ exists. Then\n",
    "\n",
    "$$E(\\sum_{i=1}^{n}g(X_i))=nE(g(X_1))\\tag{1}$$\n",
    "\n",
    "$$Var(\\sum_{i=1}^{n}g(X_i))=nVar(g(X_1))\\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Proof $(1)$:\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    &E(\\sum_{i=1}^{n}g(X_i))\\\\\n",
    "    &=E(g(X_1)+g(X_2)+...+g(X_n))\\\\\n",
    "    &=E(g(X_1))+E(g(X_2))+...+E(g(X_n))\\\\\n",
    "    &=nE(g(X_1))\\\\\n",
    "    \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Proof (2):\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    &Var(\\sum_{i=1}^{n}g(X_i))\\\\\n",
    "    &=E\\big([\\sum_{i=1}^{n}g(X_i)-E(\\sum_{i=1}^{n}g(X_i))]^2\\big)\\\\\n",
    "    &=E\\big([\\sum_{i=1}^{n}g(X_i)-nE(g(X_1))]^2\\big)\\\\\n",
    "    &=E\\big([g(X_1)-E(g(X_1))+g(X_2)-E(g(X_2))+...+g(X_n)-E(g(X_n))]^2\\big)\\\\\n",
    "    &=E\\big[g(X_1)-E(g(X_1)))^2+(g(X_2)-E(g(X_2)))^2+...(g(X_n)-E(g(X_n)))^2+2(g(X_1)-E(g(X_1))(g(X_2)-E(g(X_2)))+...+2(g(X_{n-1})-E(g(X_{n-1}))(g(X_{n})-E(g(X_{n}))))\\big]\\\\\n",
    "    &=E((g(X_1)-E(g(X_1)))^2)+...+E((g(X_n)-E(g(X_n)))^2),\\,\\text{Since } 2Cov(X_i,X_j)=0,\\forall i\\neq j\\\\\n",
    "    &=nVar(g(X_1))\\\\\n",
    "    \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem\n",
    "\n",
    "Let $X_1,...,X_n$ be a random sample of size $n$ from a population with mean $\\mu$ and variance $\\sigma^2<\\infty$. Then\n",
    "\n",
    "1. $E(\\bar{X})=\\mu$\n",
    "    - $E(\\frac{1}{n}\\sum_{i=1}^n X_i)=\\frac{1}{n}n\\mu=\\mu$\n",
    "2. $Var(\\bar{X})=\\frac{\\sigma^2}{n}$\n",
    "    - $Var(\\frac{1}{n}\\sum_{i=1}^{n}X_i)=\\frac{1}{n^2}n\\sigma^2=\\frac{\\sigma^2}{n}$\n",
    "3. $E(S^2)=\\sigma^2\\cdots(3)$\n",
    "4. Useful fact: For any numbers $x_1,...,x_n$ we have\n",
    "    - $\\sum_{i=1}^{n}(x_i-\\bar{x})^2=\\sum_{i=1}^n x_{i}^2-n\\bar{x}^2$\n",
    "        - where $\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i$\n",
    "\n",
    "- Proof $(3)$:\n",
    "    \n",
    "    $S^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\bar{X})^2$\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    E(S^2)&=\\frac{1}{n-1}\\big(E(\\sum_{i=1}^{n}X_i^2-n\\bar{X}^2)\\big),\\,using~(4)\\\\\n",
    "          &=\\frac{1}{n-1}(\\sum_{i=1}^{n}E(X_i^2)-nE(\\bar{X}^2))\\\\\n",
    "          &=\\frac{1}{n-1}(n\\cdot(\\sigma^2+\\mu^2)-n(\\frac{\\sigma^2}{n}+\\mu^2))\\\\\n",
    "          &=\\sigma^2\n",
    "    \\end{aligned}$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
