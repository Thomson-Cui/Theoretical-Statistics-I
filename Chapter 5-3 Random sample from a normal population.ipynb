{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem 5.3.1: Distributions of sample mean $\\bar{X}$ and sample variance $S^2$\n",
    "Let $X_1,...,X_n$ be a random sample from $N(\\mu,\\sigma^2)$ and let\n",
    "\n",
    "$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_i$ and $S^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\bar{X})^2$\n",
    "\n",
    "Then,\n",
    "\n",
    "(a) $\\bar{X}$ and $S^2$ are independent\n",
    "\n",
    "(b) $\\bar{X}\\sim N(\\mu,\\frac{\\sigma^2}{n})$\n",
    "\n",
    "(c) $\\frac{(n-1)S^2}{\\sigma^2}\\sim\\chi_{n-1}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of (a)\n",
    "- Note first that $S^2$ is \"over determined\" with $n+1$ terms\n",
    "\n",
    "    $X_1.X_2....,X_n,\\bar{X}$\n",
    "\n",
    "    Can write $S^2$ without $X_1$:\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    X_1 &= n\\bar{X}-(X_2+,...,+X_n)\\\\\n",
    "        &= \\bar{X} + \\sum_{i=2}^{n}(\\bar{X}-X_i)\n",
    "    \\end{aligned}$\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    S^2&=\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\bar{X})^2\\\\\n",
    "       &=\\frac{1}{n-1}((X_1-\\bar{X})^2+\\sum_{i=2}^{n}(X_i-\\bar{X})^2)\\\\ \n",
    "       &=\\frac{1}{n-1}((\\sum_{i=2}^{n}(X_i-\\bar{X}))^2+\\sum_{i=2}^{n}(X_i-\\bar{X})^2),\\,\\text{only n-1 terms}\\\\\n",
    "    \\end{aligned}$\n",
    "\n",
    "- We have written $S^2$ as a function of $n-1$ terms:\n",
    "\n",
    "    $(X_2-\\bar{X}),(X_3-\\bar{X}),...,(X_n-\\bar{X})$\n",
    "\n",
    "- Show that $\\bar{X}$ and the random vector ($X_2-\\bar{X},X_3-\\bar{X},...,X_n-\\bar{X}$) are independent\n",
    "    - then we have shown that $\\bar{X}$ and $S^2$ are independent\n",
    "        - $(X_1,...,X_n)\\to(Y_1,...,Y_n)$ show: $Y_1$ and $Y_2,...,Y_n$ are independent\n",
    "\n",
    "- Define an $n$ dimensional transformation:\n",
    "\n",
    "    $Y_1=\\bar{X},Y_2=X_2-\\bar{X},Y_3=X_3-\\bar{X},...,Y_n=X_n-\\bar{X}$\n",
    "\n",
    "- Want to show that\n",
    "\n",
    "    $f(y_1,y_2,y_3,...,y_n)=g(y_1)h(y_2,y_3,...,y_n)$\n",
    "\n",
    "    for some functions $g(\\cdot)$ and $h(\\cdot)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the inverse functions:\n",
    "\n",
    "$Y_1=\\bar{X},Y_2=X_2-\\bar{X},Y_3=X_3-\\bar{X},...,Y_n=X_n-\\bar{X}$\n",
    "\n",
    "$\\Rightarrow n$-dim Transformation\n",
    "\n",
    "\n",
    "$\n",
    "X_1= \\bar{X} + \\sum_{i=2}^{n}(\\bar{X}-X_i)=Y_1-(Y_2+Y_3+...+Y_n)\\\\\n",
    "X_2=Y_2+Y_1\\\\\n",
    "X_3=Y_3+Y_1\\\\\n",
    "X_4=Y_4+Y_1\\\\\n",
    "\\vdots\\\\\n",
    "X_n=Y_n+Y_1$\n",
    "\n",
    "$\n",
    "\\frac{\\partial x_1}{\\partial y_1} = 1, \\frac{\\partial x_1}{\\partial y_2} = -1,\\cdots, \\frac{\\partial x_1}{\\partial y_n} = -1 \\\\\n",
    "\\frac{\\partial x_2}{\\partial y_1} = 1, \\frac{\\partial x_2}{\\partial y_2} = 1,\\frac{\\partial x_2}{\\partial y_2} = 0,\\cdots,\\frac{\\partial x_2}{\\partial y_n} = 0 \\\\\n",
    "\\vdots\n",
    "$\n",
    "\n",
    "for $k=2,...,n$ we get $\\frac{\\partial x_k}{\\partial y_1} = 1$ and $\\frac{\\partial x_k}{\\partial y_k} = 1$, other derivatives are 0.\n",
    "\n",
    "The Jacobian is therefore:\n",
    "\n",
    "$\\left\\lvert\\,\\left[\\begin{array}{ccc}\n",
    "\\frac{\\delta x_{1}}{\\delta y_{1}} & \\cdots & \\frac{\\delta x_{1}}{\\delta y_{n}} \\\\\n",
    "\\vdots & & \\\\\n",
    "\\frac{\\delta x_{n}}{\\delta y_{1}} & \\cdots & \\frac{\\delta x_{n}}{\\delta y_{n}}\n",
    "\\end{array}\\right]\\right\\lvert=\n",
    "\\left|\\left[\\begin{array}{cccccc}\n",
    "1 & -1 & -1 & -1 & \\cdots & -1 \\\\\n",
    "1 & 1 & 0 & 0 & \\cdots & 0 \\\\\n",
    "1 & 0 & 1 & 0 & \\cdots & 0 \\\\\n",
    "1 & 0 & 0 & 1 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & & \\vdots \\\\\n",
    "1 & 0 & 0 & 0 & \\cdots & 1\n",
    "\\end{array}\\right]\\right|=$\n",
    "\n",
    "$\\left|\\left[\\begin{array}{cccccc}\n",
    "n & 0 & 0 & 0 & \\cdots & 0 \\\\\n",
    "1 & 1 & 0 & 0 & \\cdots & 0 \\\\\n",
    "1 & 0 & 1 & 0 & \\cdots & 0 \\\\\n",
    "1 & 0 & 0 & 1 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & & \\vdots \\\\\n",
    "1 & 0 & 0 & 0 & \\cdots & 1\n",
    "\\end{array}\\right]\\right|$=$n\\cdot 1\\cdot 1...\\cdot 1=n\\Rightarrow|J|=|n|=n$ \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the inverse functions $h_i(\\underline{y})$ and Jacobian and then\n",
    "\n",
    "    $f(\\underline{y})=f_{\\underline{X}}(h_1{(\\underline{y}),...,h_n({\\underline{y}})})|J|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assuming $X_1,...,X_n$ are i.i.d. $N(0,1)$ we have\n",
    "\n",
    "    $f_X=\\prod_{i=1}^{n}\\frac{1}{\\sqrt{2\\pi}}exp(-x_i^2/2)=(2\\pi)^{-n/2}exp(-\\frac{1}{2}\\sum_{i=1}^{n}x_i^2)$\n",
    "- Therefore\n",
    "\n",
    "    $f(\\underline{y})=(2\\pi)^{-n/2}exp(-\\frac{1}{2}((y_1-\\sum_{i=2}^{n}y_i))^2+\\sum_{i=2}^n(y_i+y_1)^2)\\cdot n$\n",
    "\n",
    "    if = $g(y_1)\\cdot h(y_2,...,y_n)$ the proof is done $\\to$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's do it.\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    f(\\underline{y})\n",
    "    &=(2\\pi)^{-n/2}exp(-\\frac{1}{2}((y_1-\\sum_{i=2}^{n}y_i))^2+\\sum_{i=2}^n(y_i+y_1)^2)\\cdot n\\\\\n",
    "    &=n(2\\pi)^{-n/2}exp(-\\frac{1}{2}(y_1^2-2y_1\\sum_{i=2}^{n}y_i+(\\sum_{i=2}^{n}y_i)^2+\\sum_{i=2}^n(y_i^2+2y_iy_1+y_1^2)))\\\\\n",
    "    &=n(2\\pi)^{-n/2}exp(-\\frac{1}{2}(ny_1^2+(\\sum_{i=2}^{n}y_i)^2+\\sum_{i=2}^{n}y_i^2))\\\\\n",
    "    &=n(2\\pi)^{-n/2}exp(-\\frac{1}{2}ny_1^2)exp(-\\frac{1}{2}((\\sum_{i=2}^{n}y_i)^2+\\sum_{i=2}^{n}y_i^2))\\\\\n",
    "    &=n(2\\pi)^{-n/2}g(y_1)h(y_2,y_3,...,y_n)\\\\\n",
    "    &\\Rightarrow Y_1 \\text{ and } (Y_2,...,Y_n) \\text{ are independent.}\\\\\n",
    "    &\\Rightarrow \\bar{X} \\text{ and } S^2 \\text{ are independent.}\n",
    "    \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the $\\chi_p^2$ distribution = Gamma($\\frac{\\sum_{i=1}^{n}p_i}{2},2$)=$\\chi_{p_1,...,p_n}^2$\n",
    "\n",
    "#### Lemma 5.3.2\n",
    "(a) If $Z\\sim N(0,1)$ then $Z^2\\sim\\chi_{1}^2$\n",
    "\n",
    "(b) If $V_1,...,V_n$ are independent and $V_i\\sim\\chi_{p_i}^2$ then\n",
    "\n",
    "$V_1,V_2,...,+V_n\\sim\\chi_{p_1+...+p_n}^2$\n",
    "\n",
    "(c) $\\frac{(n-1)S^2}{\\sigma^2}\\sim\\chi_{n-1}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof of (a)\n",
    "Seen before, just a univariate transformation of $Z\\sim N(0,1)$.\n",
    "\n",
    "#### Proof of (b)\n",
    "- Remember: $\\chi_p^{2}$ distribution = Gamma($\\frac{p}{2},2$) distribution.\n",
    "- Seen before or can show using mgfs: Sum of indep. Gammas with same $\\beta$ is a Gamma with that same $\\beta$ and $\\alpha =$ sum of the original $\\alpha$'s $\\Rightarrow V_1+...+V_n\\sim Gamma(\\sum_{i=1}^n\\frac{p_i}{2},2)$\n",
    "\n",
    "#### Proof of (c)\n",
    "- Proof by induction. Set\n",
    "\n",
    "    $\\bar{X}_k=\\frac{1}{k}\\sum_{i=1}^k X_i$ and $S_k^2=\\frac{1}{k-1}\\sum_{i=1}^k(X_i-\\bar{X}_k)^2$\n",
    "\n",
    "    and note that\n",
    "\n",
    "    $\\bar{X}_{k+1}=\\frac{k\\bar{X}_k+X_{k+1}}{k+1}$ and $kS_{k+1}^2=(k-1)S_k^2+\\frac{k}{k+1}(X_{k+1}-\\bar{X}_k)^2$\n",
    "\n",
    "- Start with $k=2$... show that $\\frac{S_2^2}{\\sigma^2}\\sim\\chi_1^2$\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    \\frac{S_2^2}{\\sigma^2}&=\\frac{1}{\\sigma^2}\\sum_{i=1}^2(X_i-\\bar{X}_2)^2\\\\\n",
    "                          &=\\frac{1}{\\sigma^2}((X_1-\\frac{X_1+X_2}{2})^2+(X_2-\\frac{X_1+X_2}{2})^2)\\\\\n",
    "                          &=\\frac{(X_1-X_2)^2}{2\\sigma^2}\n",
    "    \\end{aligned}$\n",
    "\n",
    "    Since $X_1-X_2\\sim N(0,2\\sigma^2)\\Rightarrow \\frac{X_1-X_2}{\\sqrt{2\\sigma^2}}\\sim N(0,1)\\Rightarrow \\frac{(X_1-X_2)^2}{2\\sigma^2}\\sim\\chi_1^2$\n",
    "\n",
    "- Assume that $\\frac{(k-1)S_k^2}{\\sigma^2}\\sim\\chi_{k-1}^2$ and show that $\\frac{kS_{k+1}^2}{\\sigma^2}\\sim\\chi_k^2$\n",
    "\n",
    "    - $kS_{k+1}^2=(k-1)S_k^2+\\frac{k}{k+1}(X_{k+1}-\\bar{X}_k)^2\\Rightarrow \\frac{kS_{k+1}^2}{\\sigma^2}=\\frac{(k-1)}{\\sigma^2}S_k^2+\\frac{k}{(k+1)\\sigma^2}(X_{k+1}-\\bar{X}_k)^2$\n",
    "\n",
    "        - First term: $\\frac{(k-1)}{\\sigma^2}S_k^2\\sim\\chi_{k-1}^2$\n",
    "\n",
    "        - Second term: $\\frac{k}{(k+1)\\sigma^2}(X_{k+1}-\\bar{X}_k)^2\\sim \\chi_{1}^2$\n",
    "            - $X_{k+1}\\sim N(\\mu,\\sigma^2)$\n",
    "            - $\\bar{X}_k\\sim N(\\mu,\\sigma^2/k)$\n",
    "                $X_{k+1}-\\bar{X}_k\\sim N(0,\\frac{\\sigma^2(k+1)}{k})$\n",
    "            - $\\sqrt{\\frac{k}{(k+1)\\sigma^2}}(X_{k+1}-\\bar{X}_k)\\sim N(0,1)$\n",
    "            - $\\frac{k}{(k+1)\\sigma^2}(X_{k+1}-\\bar{X}_k)^2\\sim \\chi_{1}^2$\n",
    "        - $\\Rightarrow \\frac{kS_{k+1}^2}{\\sigma^2} \\sim \\chi_k^2$\n",
    "\n",
    "- Finally, (c) was proved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If $X_1,...,X_n$ are iid $N(\\mu,\\sigma^2)$, then $\\frac{X_i-\\mu}{\\sigma}\\overset{iid}{\\operatorname*{\\sim}}N(0,1)$.\n",
    "\n",
    "$\\begin{aligned}\n",
    "&\\Rightarrow \\frac{(x_i-\\mu)^2}{\\sigma^2}\\sim\\chi_1^2\\\\\n",
    "&\\Rightarrow \\sum_{i=1}^n \\frac{(X_i-\\mu)^2}{\\sigma^2}\\sim\\chi_n^2\\\\\n",
    "&\\Rightarrow \\frac{\\sum_{i=1}^n(X_i-\\mu)^2}{\\sigma^2}\\sim\\chi_n^2\\\\\n",
    "\\end{aligned}$\n",
    "\n",
    "But $(n-1)S^2=\\sum_{i=1}^n(X_i-\\bar{X})^2$, where $\\bar{X}\\neq\\mu$, \"loose one degree of freedom\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and independence\n",
    "- It is a special property only for the normal distribution.\n",
    "#### Independence $\\Leftrightarrow$ Correlation = 0\n",
    "Let $(X_1,X_2)$ be a bivariate normal random vector. Then $X_1$ and $X_2$ are independent if and only if $\\rho=Cor(X_1,X_2)=0$\n",
    "- Recall the pdf of a bivariate normal pdf:\n",
    "$\\begin{aligned}\n",
    "f(x_1,x_2) & =\\frac{1}{2\\pi\\sigma_{1}\\sigma_{2}\\sqrt{1-\\rho^{2}}} \\exp\\left\\{-\\frac{1}{2(1-\\rho^{2})}\\left[\\frac{(x_{1}-\\mu_{1})^{2}}{\\sigma_{1}^{2}}-2\\rho\\frac{(x_{1}-\\mu_{1})(x_{2}-\\mu_{2})}{\\sigma_{1}\\sigma_{2}}+\\frac{(x_{2}-\\mu_{2})^{2}}{\\sigma_{2}^{2}}\\right]\\right\\}\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The t distribution\n",
    "Let $U$ and $V$ be independent random variables and $U\\sim N(0,1)$ and $V\\sim\\chi_p^2$. The distribution of \n",
    "\n",
    "$T = \\frac{U}{\\sqrt{V/p}}$\n",
    "\n",
    "is called the $t$ distribution with $p$ degrees of freedom, or $t_p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving the pdf for the student’s t distribution\n",
    "- Let $U\\sim N(0,1)$ and $V\\sim\\chi_p^2$ be independent.\n",
    "- Want the pdf of $T=\\frac{U}{\\sqrt{V/p}}$\n",
    "- Strategy: Do a bivariate transformation\n",
    "    - $(U,V)\\to(T,W)$ and find the marginal of $T$\n",
    "- Set $W=V$\n",
    "- Proof:\n",
    "    - $(U,V)\\to(T,W)$, $T=\\frac{U}{\\sqrt{V/p}}$, and $W=V$\n",
    "    \n",
    "        $v=w=h_1(t,w)$ and $u=t\\sqrt{V/p}=t\\sqrt{w/p}=h_2(t,w)$\n",
    "\n",
    "        $\\frac{\\partial u}{\\partial t}=\\sqrt{w/p},\\frac{\\partial u}{\\partial w}=\\frac{t}{2\\sqrt{pw}},\\frac{\\partial v}{\\partial t}=0,\\frac{\\partial v}{\\partial w}=1$\n",
    "\n",
    "        $|J|=\\sqrt{w/p}$\n",
    "\n",
    "        $\\begin{aligned}\n",
    "        f(t,w)&=f_{U,V}(u,v)|J|,(where~U,V~independent)\\\\\n",
    "              &=f(u)f(v)|J|\\\\\n",
    "              &=\\frac{1}{\\sqrt{2\\pi}}e^{-u^2/2}\\frac{1}{\\Gamma(p/2)2^{p/2}}v^{p/2-1}e^{-v/2}\\sqrt{w/p}\\\\\n",
    "              &=\\frac{1}{\\sqrt{2\\pi}2^{p/2}\\Gamma(p/2)}w^{p/2-1}exp(-\\frac{1}{2}t^2w/p-w/2)\\sqrt{w/p},t\\in(-\\infty,\\infty),w\\in(0,\\infty)\n",
    "        \\end{aligned}$\n",
    "\n",
    "        $\\begin{aligned}\n",
    "        f_T(t)\n",
    "        &=\\int_{0}^{\\infty}\\frac{1}{\\sqrt{\\pi}2^{\\frac{(p+1)}{2}}\\Gamma(p/2)}w^{p/2-1}exp(-\\frac{1}{2}t^2w/p-w/2)\\sqrt{w/p}dw\\\\\n",
    "        &\\text{set }\\alpha=\\frac{p-1}{2}+1,\\text{ and }\\beta=\\frac{1}{\\frac{t^2+p}{2p}}=\\frac{2}{t^2/p+1}\\\\\n",
    "        &=\\frac{1}{\\sqrt{\\pi}2^{\\frac{p+1}{2}}\\Gamma(p/2)\\sqrt{p}}\\Gamma(\\alpha)\\beta^{\\alpha}\\int_{0}^{\\infty}\\frac{1}{\\Gamma(\\alpha)\\beta^\\alpha}w^{\\alpha-1}e^{-w/\\beta}dw\\\\\n",
    "        &=\\frac{1}{\\sqrt{\\pi}2^{\\frac{p+1}{2}}\\Gamma(p/2)\\sqrt{p}}\\Gamma(\\alpha)\\beta^{\\alpha}\\\\\n",
    "        &=\\frac{\\Gamma\\left(\\frac{p+1}{2}\\right)}{\\Gamma\\left(\\frac{p}{2}\\right)}\\frac{1}{(p\\pi)^{1/2}}\\frac{1}{\\left(1+x^{2}/p\\right)^{(p+1)/2}},x\\in(-\\infty,\\infty)\\\\\n",
    "        &\\text{The parameter p (freedom degree) is an integer.}\n",
    "        \\end{aligned}$\n",
    "- When $p\\to\\infty$, the $t_p$ approaches $N(0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The $T$ Statistic\n",
    "#### The $T$ Statistic\n",
    "Let $X_1,X_2,...,X_n$ be a random sample from a normal distribution with mean $\\mu$ and variance $\\sigma^2$. Then the statistic\n",
    "\n",
    "$T=\\frac{\\bar{X}-\\mu}{S/\\sqrt{n}}\\sim t_{n-1}$\n",
    "\n",
    "has $t$ distribution with $n-1$ degrees of freedom, or $t_{n-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Proof:\n",
    "\n",
    "    - know: $\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}}\\sim N(0,1)$ and $\\frac{(n-1)S^2}{\\sigma^2}\\sim\\chi_{n-1}^2$\n",
    "\n",
    "    - $\\bar{X}$ and $S^2$ are independent $\\Rightarrow \\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}}$ and $\\frac{(n-1)S^2}{\\sigma^2}$ are independent.\n",
    "        - $T = \\frac{U}{\\sqrt{V/p}}$ = $\\Rightarrow \\frac{\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}}}{\\sqrt{\\frac{(n-1)S^2}{\\sigma^2(n-1)}}}\\sim t_{n-1}$\n",
    "        - $\\Rightarrow \\frac{\\bar{X}-\\mu}{S/\\sqrt{n}}\\sim t_{n-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snedecor’s F distribution1\n",
    "\n",
    "- Comparing two variances: $S_1^2/S_2^2$\n",
    "- Linear models: Ratio of sums-of-squares\n",
    "\n",
    "#### Def: $F_{u,v}$ distribution\n",
    "\n",
    "Let $X\\sim\\chi_p^2$ and $Y\\sim\\chi_q^2$ be independent random variables. The distribution of \n",
    "\n",
    "$U = \\frac{X/p}{Y/q}\\sim F_{p,q}$\n",
    "\n",
    "is called the $F$ distribution with $p$ and $q$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof of F-distribution\n",
    "$X\\sim\\chi_p^2,Y\\sim\\chi_q^2,U=\\frac{X/p}{Y/q}$\n",
    "Define V=Y, f(x,y)=f(x)f(y)\n",
    "- Find $f(u,v)$ and $f(u)=\\int f(u,v)dv$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-distribution - pdf\n",
    "\n",
    "$f(x)=\\frac{\\Gamma\\left(\\frac{p+q}{2}\\right)}{\\Gamma\\left(\\frac{p}{2}\\right) \\Gamma\\left(\\frac{q}{2}\\right)}\\left(\\frac{p}{q}\\right)^{p / 2} \\frac{x^{(p / 2)-1}}{(1+(p / q) x)^{(p+q) / 2}}, \\quad 0<x<\\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The $F$ Statistic\n",
    "\n",
    "#### The $F$ Statistic\n",
    "\n",
    "- Let $X_1,X_2,...,X_n$ be a random sample from a normal distribution with mean $\\mu_X$ and variance $\\sigma_X^2$.\n",
    "- Let $Y_1,Y_2,....,X_m$ be a random sample from a normal distribution with mean $\\mu_Y$ and variance $\\sigma_Y^2$.\n",
    "\n",
    "Then the statistic\n",
    "\n",
    "$F = \\frac{S_X^2/\\sigma_X^2}{S_Y^2/\\sigma_Y^2}\\sim F_{n-1,m-1}$\n",
    "\n",
    "has F distribution with $n-1$ and $m-1$ degrees of freedom, or $F_{n-1,m-1}$\n",
    "\n",
    "- $\\frac{(n-1)S_X^2}{\\sigma_X^2}\\sim\\chi_{n-1}^2$ \n",
    "- $\\frac{(m-1)S_Y^2}{\\sigma_Y^2}\\sim\\chi_{m-1}^2$\n",
    "- $\\frac{\\frac{(n-1)S_X^2}{\\sigma_X^2}/(n-1)}{\\frac{(m-1)S_Y^2}{\\sigma_Y^2}/(m-1)}\\sim F_{n-1,m-1}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-distribution – properties\n",
    "\n",
    "Some useful (univariate) transformations of the F distribution\n",
    "\n",
    "#### Theorem 5.3.8\n",
    "1. If $X\\sim F_{p,q}$ then $1/X\\sim F_{q,p}$.\n",
    "2. If $X\\sim t_q$, then $X^2\\sim F_{1,q}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T and F statistics – uses\n",
    "- The T statistic is used in inference of the mean of a normal distribution when variance is unknown, e.g.\n",
    "    - Population mean of one or two populations\n",
    "        - t-test, two-sample t-test, paried t-test\n",
    "    - Regression coefficients in a normal linear regression model\n",
    "- The $F$ statistics is used in many situations, e.g.\n",
    "    - to test for equality of variances from two independent populations\n",
    "    - Analysis of Variance (ANOVA)\n",
    "    - comparing nested models in normal linear regression"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
