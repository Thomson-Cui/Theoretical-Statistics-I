{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53699d2f",
   "metadata": {},
   "source": [
    "## Expected values\n",
    "\n",
    "`Definition`: Let $X\\sim f(x)$. The *expected value* of $g(X)$ is defined as\n",
    "$$\\left.\\operatorname{E}(g(X))=\\left\\{\\begin{array}{ll}\\int_{-\\infty}^{\\infty}g(x) f_{X}(x) dx&\\text{if X is continuous}\\\\\\sum_{x\\in\\mathcal{X}}g(x) f_{X}(x)=\\sum_{x\\in\\mathcal{X}}g(x)P(X=x)&\\text{if X is discrete}\\end{array}\\right.\\right.$$\n",
    "- If $\\mathrm{E}(|g(X)|)=\\int_{-\\infty}^{\\infty}|g(x)|f(x)dx=\\infty$, we say that $E(g(X))$ does not exist.\n",
    "- In particular, the mean of $X$ is:\n",
    "$$E(x)=\\int_{-\\infty}^{\\infty}xf(x)dx,\\text{ if cont}$$\n",
    "$$E(x)=\\sum_{x}xf(x),\\text{ if discrete}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbaabb",
   "metadata": {},
   "source": [
    "### Exponential distribution\n",
    "Exponential distribution $X\\sim\\mathrm{Expo}(\\beta)$ with $\\beta>0$ and pdf\n",
    "\n",
    "$$f(x)=\\begin{cases}\\begin{array}{ll}\\frac{1}{\\beta}e^{-x/\\beta}&,x\\geq0\\\\0&,x<0\\end{array}&&\\end{cases}$$\n",
    "\n",
    "### Gamma distribution\n",
    "Gamma distribution Gamma($\\alpha,\\beta$) with $\\alpha>0, \\beta>0$ and pdf\n",
    "\n",
    "$$f(x)=\\left\\{\\begin{array}{ll}\\frac{1}{\\Gamma(\\alpha)\\beta^{\\alpha}}x^{(\\alpha-1)}e^{-x/\\beta}&,x\\geq0\\\\0&,x<0\\end{array}\\right.$$\n",
    "- **Note**: Gamma($\\alpha=1,\\beta$)=Expo($\\beta$)\n",
    "\n",
    "Let $X\\sim$ Gamma($\\alpha,\\beta$)\n",
    "- $E(X)=\\alpha\\beta$\n",
    "- $E(X^2)=(\\alpha+1)\\alpha\\beta^2$\n",
    "- $Var(X)=\\alpha\\beta^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83a367",
   "metadata": {},
   "source": [
    "## Some useful facts\n",
    "\n",
    "Gamma function $\\Gamma(\\alpha)=\\int_0^\\infty t^{\\alpha-1}e^{-t}dt, \\alpha>0$\n",
    "- If $n$ is an integer: $\\Gamma(n)=(n-1)!$\n",
    "- $\\Gamma(\\alpha)=(\\alpha-1)\\Gamma(\\alpha-1)$\n",
    "- $\\Gamma(0.5)=\\sqrt{\\pi}$\n",
    "\n",
    "Integration by parts: $\\int uv^{\\prime}=uv-\\int u^{\\prime}v$\n",
    "\n",
    "Taylor series for $e^{\\lambda}$: $e^\\lambda=\\sum_{x=0}^\\infty\\frac{\\lambda^x}{x!}$\n",
    "\n",
    "$\\int\\frac1{1+x^2}=\\tan^{-1}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31031ece",
   "metadata": {},
   "source": [
    "### Poisson distribution\n",
    "Poisson($\\lambda$) with $\\lambda>0$ and pmf\n",
    "$f(x)=\\begin{cases}\\begin{array}{ll}\\frac{e^{-\\lambda}\\lambda^{x}}{x!}&,&x=0,1,2,\\ldots\\\\0&,&\\mathrm{otherwise}\\end{array}&&\\end{cases}$\n",
    "- $\\sum_{x=0}^{\\infty}\\frac{e^{-\\lambda}\\lambda^{x}}{x!}=e^{-\\lambda}\\sum_{x=0}^{\\infty}\\frac{\\lambda^{x}}{x!}=e^{-\\lambda}e^{\\lambda}=1$\n",
    "- $E(X) = \\lambda$\n",
    "- $E(X^2)=\\lambda^2+\\lambda$\n",
    "- $Var(X)=\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc93163",
   "metadata": {},
   "source": [
    "### Cauchy distribution\n",
    "$f(x)=\\frac1{\\pi(1+x^2)}\\quad\\mathrm{~,~}x\\in\\mathbb{R}$\n",
    "\n",
    "$\\begin{aligned}&\\int_{-\\infty}^{\\infty}\\frac{1}{\\pi}\\frac{1}{(1+x^{2})}dx=\\frac{1}{\\pi}\\tan^{-1}(x)|_{x=-\\infty}^{\\infty}=\\frac{1}{\\pi}(\\frac{\\pi}{2}-(-\\frac{\\pi}{2}))=\\frac{\\pi}{\\pi}=1\\end{aligned}$\n",
    "\n",
    "E(X) does not exist, because $\\int_{\\infty}^{-\\infty}(x)\\frac{1}{\\pi}\\frac{1}{(1+x^{2})}dx=\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a431773",
   "metadata": {},
   "source": [
    "## A note on methods\n",
    "We can approach $E(g(X))$ in two ways:\n",
    "1. Using the pdf of $X$:\n",
    "$E(g(X))=\\int_{-\\infty}^{\\infty}g(x)f(x)dx$\n",
    "2. Using the pdf of $Y=g(X)$:\n",
    "$E(g(X))=E(Y)=\\int_{-\\infty}^{\\infty}yf_Y(y)dy$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0650fdd",
   "metadata": {},
   "source": [
    "## Properties of expectation\n",
    "**Theorem**\n",
    "Let $X$ be a random variable and let $a, b, c$ be constants, \n",
    "\n",
    "and suppose that $E(g_1(X))$ and $E(g_2(X))$ exist.\n",
    "- $E(ag_1(X)+bg_2(X)+c)=aE(g_1(X))+bE(g_2(X))+c$\n",
    "- $\\mathrm{If~}g_1(x)\\geq0\\text{ for all }x\\mathrm{~then~}E(g_1(X))\\geq0$\n",
    "- $\\mathrm{If~}g_1(x)\\geq g_2(x)\\text{ for all }x\\mathrm{~then~}E(g_1(X))\\geq E(g_2(X))$\n",
    "- $\\mathrm{If~}a\\leq g(x)\\leq b\\text{ for all }x\\mathrm{~then~}a\\leq E(g(x))\\leq b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2077f47",
   "metadata": {},
   "source": [
    "## Moments - Section 2.3\n",
    "Let $n$ be a *positive integer* and $X$ be a random variable\n",
    "- The $n$-th moment of $X$ is $\\mu_n^{\\prime}=E\\left(X^n\\right)$.\n",
    "- The $n$-th central moment of $X$ is $\\mu_n=E\\left((X-\\mu)^n\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c226d72",
   "metadata": {},
   "source": [
    "## Variance\n",
    "The mean or expected value of a r.v. $X$ is the 1st moment:\n",
    "$\\mu_1^{\\prime}=\\operatorname{E}(X)\\equiv\\mu$\n",
    "\n",
    "The variance of a r.v. X is the 2nd central moment $\\mathrm{Var}(X)=E\\left((X-\\mu)^2\\right)\\equiv\\sigma^2$\n",
    "\n",
    "The standard deviation of $X$ is defined as $\\sigma=\\sqrt{\\mathrm{Var}(X)}$\n",
    "\n",
    "- $\\mathrm{Var}(ax+b)=a^2\\mathrm{Var}(x)$\n",
    "- $\\mathrm{Var}(x)=E(x^{2})-E(x)^{2}$\n",
    "- $E(x^{2})=\\int x^{2}f(x)dx$\n",
    "- $Var(x)=\\int(x-\\mu_{x})^{2}f(x)dx$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae9a93",
   "metadata": {},
   "source": [
    "## Moment generating functions (mgf)\n",
    "\n",
    "Mgf is a very useful theoretical tool,\n",
    "- to characterize a distribution\n",
    "- for limits\n",
    "- to prove (a version of) the Central Limit Theorem!\n",
    "\n",
    "### Definition\n",
    "Let $X\\sim F(x)$. The moment generating function (mgf) of $X$ is defined as\n",
    "\n",
    "$$M_X(t)=E\\left(e^{tX}\\right)$$\n",
    "\n",
    "if the expectation exists for $t$ in a neighborhood of 0.\n",
    "\n",
    "### Moment generating functions\n",
    "`Theorem`: If a r.v. $X$ has mgf $M_X(t)$ then\n",
    "\n",
    "$$E\\left(X^{n}\\right)=\\left.\\frac{d^{n}}{dt^{n}}M_{X}(t)\\right|_{t=0}$$\n",
    "\n",
    "Find the mgf for the Gamma and Poisson distributions and use it to gnerate the first two moments.\n",
    "\n",
    "#### Example for Gamma distribution\n",
    "Let $X\\sim Gamma(\\alpha,\\beta)$, $f(x)=\\left\\{\\begin{array}{ll}\\frac{1}{\\Gamma(\\alpha)\\beta^{\\alpha}}x^{(\\alpha-1)}e^{-x/\\beta}&,x\\geq0\\\\0&,x<0\\end{array}\\right.$, with $\\alpha>0, \\beta>0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16d33f",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{align}\n",
    "M_X(t) &= E(e^{tX}) \\\\\n",
    "       &= \\int_{-\\infty}^{\\infty} e^{tx} f(x) \\, dx \\\\\n",
    "       &= \\int_{0}^{\\infty} e^{tx} \\frac{1}{\\Gamma(\\alpha)\\beta^{\\alpha}}x^{\\alpha-1}e^{-x/\\beta} \\, dx &(\\text{since } x \\geq 0 \\text{ for Gamma}) \\\\\n",
    "       &= \\int_{0}^{\\infty} \\frac{1}{\\Gamma(\\alpha)\\beta^{\\alpha}} x^{\\alpha-1} e^{-x/\\beta + tx} \\, dx &\\left(\\text{let } -\\frac{x}{\\beta} + tx = -\\frac{x}{\\hat{\\beta}}, \\, \\hat{\\beta} = \\frac{\\beta}{1 - t\\beta}, \\, t \\neq \\frac{1}{\\beta}\\right) \\\\\n",
    "       &= \\frac{1}{\\beta^{\\alpha}} \\hat{\\beta}^{\\alpha} \\int_{0}^{\\infty} \\frac{1}{\\Gamma(\\alpha)\\hat{\\beta}^{\\alpha}} x^{\\alpha-1} e^{-x/\\hat{\\beta}} \\, dx \\\\\n",
    "       &= \\frac{\\hat{\\beta}^{\\alpha}}{\\beta^{\\alpha}} &(\\hat{\\beta} = \\frac{\\beta}{1 - t\\beta},\\,\\hat{\\beta}>0, \\, t \\neq \\frac{1}{\\beta}) \\\\\n",
    "       &= \\frac{\\beta^{\\alpha}}{\\beta^{\\alpha}(1 - t\\beta)^{\\alpha}} \\\\\n",
    "       &= (1 - \\beta t)^{-\\alpha}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64308f",
   "metadata": {},
   "source": [
    "Since $\\hat{\\beta} = \\frac{\\beta}{1 - t\\beta},\\,\\hat{\\beta}>0$, we can get $1 - t\\beta>0$, thus $t<\\frac{1}{\\beta}$.\n",
    "\n",
    "Saw before: $E(X)=\\alpha\\beta$, $E(X^2)=\\alpha(\\alpha+1)\\beta^2$, let's vertify it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa07016",
   "metadata": {},
   "source": [
    "$E(X)=\\frac{d}{dt}M(t)|_{t=0}=\\frac{d}{dt}(1-\\beta t)^{-\\alpha}|_{t=0}=-\\alpha(1-\\beta t)^{-(\\alpha+1)}(-\\beta)|_{t>0}=\\alpha\\beta(1-\\beta t)^{-(\\alpha+1)}|_{t=0}=\\alpha\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe549e9f",
   "metadata": {},
   "source": [
    "$E(X^2)=\\frac{d^2}{dt^2}M(t)|_{t=0}=\\frac{d}{dt}\\alpha\\beta(1-\\beta t)^{-(\\alpha+1)}|_{t=0}=-\\alpha\\beta(\\alpha+1)(1-\\beta t)^{-(\\alpha+2)}(-\\beta)|_{t-0}=\\alpha(\\alpha+1)\\beta^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c71e3c",
   "metadata": {},
   "source": [
    "#### Example for Poisson distribution\n",
    "\n",
    "Poisson($\\lambda$) with $\\lambda>0$ and pmf\n",
    "$f(x)=\\begin{cases}\\begin{array}{ll}\\frac{e^{-\\lambda}\\lambda^{x}}{x!}&,&x=0,1,2,\\ldots\\\\0&,&\\mathrm{otherwise}\\end{array}&&\\end{cases}$, \n",
    "\n",
    "`Pre-knowledge`\n",
    "\n",
    "- cdf:$\\sum_{x=0}^{\\infty}\\frac{e^{-\\lambda x}}{x!}=1$\n",
    "- $\\begin{aligned}\\sum_{x=0}^\\infty\\frac{a^x}{x!}=e^a\\end{aligned}$\n",
    "- $e^{tx}=(e^t)^x$\n",
    "- $E(X) = \\lambda$\n",
    "- $E(X^2)=\\lambda^2+\\lambda$\n",
    "- $(uv)'=u'v+uv'$\n",
    "- $\\left(\\frac{u}{v}\\right)'=\\frac{v\\cdot u'-u\\cdot v'}{v^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1f26c",
   "metadata": {},
   "source": [
    "$\\begin{align}\n",
    "M(t)&=E(e^{tx}) \\\\\n",
    "    &=\\sum_{x=0}^{\\infty}\\frac{e^{tx}e^{-\\lambda}\\lambda^{x}}{x!} \\\\\n",
    "    &=e^{-\\lambda}\\sum_{x=0}^{\\infty}\\frac{[e^{t}\\lambda]^x}{x!},\\,(a = e^{t}\\lambda) \\\\\n",
    "    &=e^{-\\lambda}e^{e^{t}\\lambda} \\\\\n",
    "    &=e^{\\lambda e^{t} - \\lambda},\\,\\text{ or }exp(\\lambda exp(t) - \\lambda) \\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82584367",
   "metadata": {},
   "source": [
    "$\\begin{align}\n",
    "E(X)&=\\frac{d}{dt}M(t)|_{t=0} \\\\\n",
    "    &=\\frac{d}{dt}exp(\\lambda exp(t)-\\lambda)|_{t=0} \\\\\n",
    "    &=exp(\\lambda exp(t)-\\lambda)·\\lambda exp(t)|_{t=0} \\\\\n",
    "    &=\\lambda\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a80e9f",
   "metadata": {},
   "source": [
    "$\\begin{align}\n",
    "E(X^2)&=\\frac{d}{dt} exp(\\lambda exp(t)-\\lambda)·\\lambda exp(t)|_{t=0} \\\\\n",
    "      &=\\lambda\\exp(\\lambda\\exp(t)-\\lambda+t)(\\lambda exp(t)+1)|_{t=0} \\\\\n",
    "      &=\\lambda^2+\\lambda\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4d012",
   "metadata": {},
   "source": [
    "## Mgfs uniquely define a distribution\n",
    "\n",
    "Mgfs (**not moments**) **uniquely** characterize a distribution\n",
    "\n",
    "### Theorem\n",
    "\n",
    "Let $F_X(x)$ and $F_Y(y)$ be cdfs for **whom all moments exists**.\n",
    "- (a) If $X$ and $Y$ have **bounded support**, then\n",
    "    \n",
    "    $F_X(u)=F_Y(u),\\forall u\\quad\\mathrm{iff}\\quad E(X^k)=E(Y^k)\\mathrm{~}\\forall k=0,1,2,\\ldots $\n",
    "    \n",
    "    \n",
    "- (b) If mgfs exist and $M_X(t) = M_Y(t)$ for all $t$ in a neighborhood of 0, then $F_X(u) = F_Y(u)$ for all $u$\n",
    "    - Remember: If $F_X(u)=F_Y(u),\\forall u$ then $X\\overset{D}{\\operatorname*{=}}Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc8269",
   "metadata": {},
   "source": [
    "## More on the Theorem\n",
    "\n",
    "1. Note: Moments $E(X^k)$ can exist even when the mgf does not\n",
    "2. Part b): If both $M_X(t)$ and $M_Y(t)$ exist\n",
    "\n",
    "    - $M_X(t)=M_Y(t)\\quad\\Leftrightarrow\\quad X\\triangleq Y$\n",
    "    \n",
    "    - So, just like the cdf and the pdf, the moment generating function (if it exists) uniquely determines the distribution of $X$\n",
    " \n",
    " \n",
    "3. Generally the moments themselves $E(X^k)$ do not uniquely determine a distribution\n",
    "    - Can have $X$ and $Y$ with same moments for all $k$ but different distribution (and different mgfs)\n",
    "\n",
    "4. Part a): If X and Y have bounded support we have\n",
    "- $\\text{All moments equal}\\Leftrightarrow\\quad X\\overset{\\mathrm{D}}{\\operatorname*{=}}Y$\n",
    "- So in that special case, the infinite sequence of moments does uniquely determine the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394a616d",
   "metadata": {},
   "source": [
    "## Convergence of mgfs\n",
    "\n",
    "Convergence of mgfs implies convergence of cdf’s\n",
    "\n",
    "### Theorem\n",
    "Let $X_1,X_2,X_3,...$ be a sequence of random variables with mgfs $M_{X_i}(t)$, $i=1,2,3,...$ and suppose that\n",
    "\n",
    "$$\\lim_{i\\to\\infty}M_{X_i}(t)=M_X(t),\\,\\forall t\\text{ in a neighborhood of 0}$$\n",
    "\n",
    "and that $M_X(t)$ is a mgf. Then there exists a unique cdf $F_X$ whose moments are determined by $M_X(t)$ and \n",
    "\n",
    "$$\\lim_{i\\to\\infty}F_{X_i}(x)=F_X(x),\\,\\text{(It means convergence in distribution)}$$\n",
    "\n",
    "for all $x$ where $F_X(x)$ is continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb8a88",
   "metadata": {},
   "source": [
    "## Poisson approximation to a Binomial\n",
    "\n",
    "Let $X_1, X_2, X_3,...$ be a sequence of random variables where\n",
    "\n",
    "$$X_n\\sim\\mathrm{Binomial}\\left(n,\\frac\\lambda n\\right)\\quad n\\in\\mathbb{N},\\lambda>0$$\n",
    "\n",
    "As $n\\to\\infty$ the distribution of $X_n$ approaches the Poisson distribution.\n",
    "- So for large $n$ we can approximate the Binomial$(n, p)$ distribution with a Poisson$(np)$ distribution ($*$)\n",
    "\n",
    "####  Pre-knowledge\n",
    "The limit identity: $\\lim_{n\\to\\infty}\\left(1+\\frac{x}{n}\\right)^n\\to e^x\\quad\\text{as}\\quad n\\to\\infty$\n",
    "\n",
    "Let $X\\sim\\mathrm{binomial}(n,p)$, that is, $P(X=x)=\\binom{n}{x}p^{x}(1-p)^{n-x},\\quad x=0,1,\\ldots,n.$\n",
    "\n",
    "- $E(X) = np$\n",
    "- $E(X^2) = n(n-1)p^2+np$\n",
    "- $Var(X) = np(1-p)$\n",
    "\n",
    "#### Proof: $(*)$\n",
    "\n",
    "About Poisson Distribution mgf, we have,\n",
    "\n",
    "$\\begin{align}\n",
    "M_Y(t)&=E(e^{tx}) \\\\\n",
    "    &=\\sum_{x=0}^{\\infty}\\frac{e^{tx}e^{-\\lambda}\\lambda^{x}}{x!} \\\\\n",
    "    &=e^{-\\lambda}\\sum_{x=0}^{\\infty}\\frac{[e^{t}\\lambda]^x}{x!},\\,(a = e^{t}\\lambda) \\\\\n",
    "    &=e^{-\\lambda}e^{e^{t}\\lambda} \\\\\n",
    "    &=e^{\\lambda e^{t} - \\lambda},\\,\\text{ or }exp(\\lambda exp(t) - \\lambda) \\\\\n",
    "\\end{align}$\n",
    "\n",
    "About Bonomial Distribution mgf, we have,\n",
    "\n",
    "$\\begin{align}\n",
    "M_{X}(t)&=\\sum_{x=0}^{n}e^{tx}\\begin{pmatrix}n\\\\x\\end{pmatrix}p^{x}(1-p)^{n-x} \\\\\n",
    "        &=\\sum_{x=0}^{n}\\begin{pmatrix}n\\\\x\\end{pmatrix}(pe^{t})^{x}(1-p)^{n-x} \\\\\n",
    "\\end{align}$\n",
    "\n",
    "Using special formular: $\\sum_{x=0}^{n}\\binom{n}{x} u^{x}v^{n-x}=(u+v)^{n}.$\n",
    "\n",
    "Therefore, $M_X(t)=\\left[pe^t+(1-p)\\right]^n$\n",
    "\n",
    "Since $\\lim_{n\\to\\infty}\\left(1+\\frac{a_n}n\\right)^n=e^a$, we have\n",
    "\n",
    "$\\begin{align}\n",
    "M_X(t)&=\\lim_{n\\to\\infty}\\left[pe^t+(1-p)\\right]^n \\\\\n",
    "      &=\\lim_{n\\to\\infty}\\left[1+\\frac{1}{n}(e^{t}-1)(np)\\right]^{n} \\\\\n",
    "      &=\\lim_{n\\to\\infty}\\left[1+\\frac{1}{n}(e^{t}-1)\\lambda\\right]^{n} \\\\\n",
    "      &=e^{\\lambda e^{t} - \\lambda} \\\\\n",
    "      &=M_Y(t)\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a8416",
   "metadata": {},
   "source": [
    "## Some useful facts\n",
    "\n",
    "Binomial Theorem\n",
    "\n",
    "$$(x+y)^n=\\sum_{i=1}^n\\binom nix^iy^{n-i},\\,\\forall x, y\\in\\mathbb{R},n\\in\\mathbb{N}$$\n",
    "\n",
    "A useful limit. If $\\lim_{n\\to\\infty}a_n=a$ then\n",
    "\n",
    "$$\\lim_{n\\to\\infty}\\left(1+\\frac{a_n}n\\right)^n=e^a$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b335785",
   "metadata": {},
   "source": [
    "## More on mgfs\n",
    "\n",
    "### Theorem\n",
    "\n",
    "Let $X$ be a random variable, $a,b$ constants and $Y = aX + b$. Then\n",
    "\n",
    "$$M_Y(t)=e^{bt}M_X(at)$$\n",
    "\n",
    "`Proof:`\n",
    "\n",
    "$\\begin{align}\n",
    "M_Y(t)&=E(e^{ty})\\\\\n",
    "      &=E(e^{t(ax+b)}))\\\\\n",
    "      &=E(e^{tax}e^{tb})\\\\\n",
    "      &=e^{tb}E(e^{tax})\\\\\n",
    "      &=e^{tb}M_X(at)\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b2ee6",
   "metadata": {},
   "source": [
    "## Other special moments\n",
    "- Mean: First moment,$\\mu=E(X)$\n",
    "- Variance: Second central moment, $\\mu_2=E((X-\\mu)^2)=\\sigma^2$\n",
    "- Skewness: $\\alpha_3=\\frac{\\mu_3}{(\\mu_2)^{3/2}}=\\frac{\\mu_3}{\\sigma^3},\\,\\text{ where }\\mu_3=E((X-\\mu)^3)$\n",
    "    - Measures lack of symmetry\n",
    "    - A pdf $f(x)$ is symmetric about $a$ if\n",
    "        - $f(a-\\epsilon)=f(a+\\epsilon)\\quad\\forall\\epsilon>0$\n",
    "        - f symmetric $\\Leftrightarrow$ $\\alpha_3=0$\n",
    "        - f left skewed $\\Leftrightarrow$ $\\alpha_3<0$\n",
    "        - f right skewed $\\Leftrightarrow$ $\\alpha_3>0$\n",
    "- Kurtosis: $\\alpha_4=\\frac{\\mu_4}{\\mu_2^2}=\\frac{\\mu_4}{\\sigma^4}$\n",
    "    - Measures \"flatness\" versus \"peakedness\" of $f(x)$\n",
    "- Mode of a distribution is a value a such that $f(a)\\geq f(x)$ for all $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d732eff3",
   "metadata": {},
   "source": [
    "## Quantiles of a distribution\n",
    "\n",
    "If $X$ is a r.v. and $0 < p < 1$ then the value up is called the $p$-th quantile of $X$ if\n",
    "\n",
    "$$F(u_p)\\geq p\\text{ and }1-F(u_p)\\geq 1-p$$\n",
    "\n",
    "If $X$ is discrete we can define\n",
    "\n",
    "$$u_p=\\min\\{x:F(x)=p\\}$$\n",
    "\n",
    "Special cases:\n",
    "- 1st quartile $Q_1 = u_{0.25}$\n",
    "- Median $Q_2 = m = u_{0.50}$\n",
    "- 3rdt quartile $Q_3 = u_{0.75}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
